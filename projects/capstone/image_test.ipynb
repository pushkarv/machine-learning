{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushkar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13430651332300922176\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1499457126\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7232249515491861987\n",
      "physical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape:  <PIL.Image.Image image mode=L size=224x224 at 0x13583F93550>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def plot_histogram(image):\n",
    "    hist,bins = np.histogram(image.flatten(),256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "    plt.plot(cdf_normalized, color = 'b')\n",
    "    plt.hist(image.flatten(),256,[0,256], color = 'r')\n",
    "    plt.xlim([0,256])\n",
    "    plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "    plt.show()\n",
    "\n",
    "def equalize_histogram(img, grid_size):\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    cl1 = clahe.apply(img)\n",
    "    return cl1\n",
    "\n",
    "# img = cv2.imread('./images/train/c0/img_34.jpg', 0)\n",
    "# equalized_img = equalize_histogram(img,16)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "# ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "def equalize_histogram(local_img, grid_size):\n",
    "#    local_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    equalized_img = clahe.apply(local_img)\n",
    "    return equalized_img\n",
    "\n",
    "def hisEqulColor(img):\n",
    "    ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\n",
    "    channels=cv2.split(ycrcb)\n",
    "    print (\"channels: \", len(channels))\n",
    "    cv2.equalizeHist(channels[0],channels[0])\n",
    "    cv2.merge(channels,ycrcb)\n",
    "    cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\n",
    "    return img\n",
    "    \n",
    "img = image.load_img('./images/train/c5/img_56.jpg', target_size=(224, 224), grayscale=True)\n",
    "print(\"original image shape: \", img)\n",
    "img = np.array(img)\n",
    "# eq_img = equalize_histogram(img,16)\n",
    "# plt.imshow(eq_img)\n",
    "# plt.show()\n",
    "# x = image.img_to_array(img)\n",
    "# print(x.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "kernel = np.ones((8,8),np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "plt.imshow(gradient)\n",
    "plt.show()\n",
    "\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "plt.imshow(tophat)\n",
    "plt.show()\n",
    "\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "plt.imshow(blackhat)\n",
    "plt.show()\n",
    "\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "plt.imshow(dilation)\n",
    "plt.show()\n",
    "\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "plt.imshow(contour)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Images...\n",
      "Number of Categories:  10\n",
      "Categories:  ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
      "(15200,) (3800,) (15200,) (3800,)\n",
      "3800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import datetime, random, pickle\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, ActivityRegularization\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "import sys\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def loadImages(path):\n",
    "    data = load_files(path)\n",
    "    files = data['filenames']\n",
    "    targets = data['target']\n",
    "    target_names = data['target_names']\n",
    "    return files, targets, target_names\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    #equalize histogram\n",
    "    #equalized_img = equalize_histogram(img_array, 16)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    print (img_paths)\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# ## Load the Data\n",
    "\n",
    "print (\"Loading Images...\")\n",
    "path = \"images/train\"\n",
    "files, targets, target_names = loadImages(path)\n",
    "# predict_files = np.array(glob(\"images/test/*\"))[1:10]\n",
    "print('Number of Categories: ', len(target_names))\n",
    "print('Categories: ', target_names)\n",
    "\n",
    "# Split the original training sets into training & testing sets\n",
    "train_files, test_files, train_targets, test_targets = train_test_split(files, targets, test_size=0.20, random_state=40)\n",
    "\n",
    "print(train_files.shape, test_files.shape, train_targets.shape, test_targets.shape)\n",
    "print(len(test_files))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image tensors\n",
      "['images/train\\\\c3\\\\img_24663.jpg' 'images/train\\\\c8\\\\img_98810.jpg'\n",
      " 'images/train\\\\c9\\\\img_67390.jpg' ... 'images/train\\\\c7\\\\img_31727.jpg'\n",
      " 'images/train\\\\c7\\\\img_82756.jpg' 'images/train\\\\c5\\\\img_21995.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15200/15200 [01:31<00:00, 166.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/train\\\\c5\\\\img_68264.jpg' 'images/train\\\\c6\\\\img_69335.jpg'\n",
      " 'images/train\\\\c2\\\\img_12280.jpg' ... 'images/train\\\\c8\\\\img_6916.jpg'\n",
      " 'images/train\\\\c6\\\\img_21610.jpg' 'images/train\\\\c5\\\\img_46343.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3800/3800 [00:28<00:00, 134.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train tensors: (15200, 224, 224, 3)\n",
      "Size of test tensors: (3800, 224, 224, 3)\n",
      "Size of test targets: (3800,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating image tensors\")\n",
    "\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32') / 255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32') / 255\n",
    "\n",
    "train_targets_onehot = np_utils.to_categorical(np.array(train_targets), 10)\n",
    "test_targets_onehot = np_utils.to_categorical(np.array(test_targets), 10)\n",
    "\n",
    "print(\"Size of train tensors: \" + str(train_tensors.shape))\n",
    "print(\"Size of test tensors: \" + str(test_tensors.shape))\n",
    "print(\"Size of test targets: \" + str(test_targets.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models\\create_base_model2018-03-1477_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 21.89%\n",
      "./saved_models\\create_base_model2018-03-1495_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 20.87%\n",
      "./saved_models\\create_base_model2018-03-1619_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 28.45%\n",
      "./saved_models\\create_base_model2018-03-1880_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 33.76%\n",
      "./saved_models\\create_base_model2018-03-3147_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.79%\n",
      "./saved_models\\create_base_model2018-03-3154_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 13.45%\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def predict_distraction(model):\n",
    "    print(\"Evaluating...\")\n",
    "    scores = model.evaluate(test_tensors, test_targets_onehot, verbose=0)\n",
    "    print(\"Evaluation %s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "    return\n",
    "\n",
    "model_files = glob.glob('./saved_models/create_base_model2018*.hdf5')\n",
    "for m in model_files:\n",
    "    print(m)\n",
    "    model = load_model(m)\n",
    "    predict_distraction(model)\n",
    "    p = model.predict(test_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# print(test_targets_onehot)\n",
    "#print(np.argmax(p, axis=0))\n",
    "# print(np.argmax(p[1,1:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models\\base4.hdf5\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1860\u001b[0m             \u001b[0mf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1861\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1862\u001b[0m             \u001b[1;31m# And copy it under a file with the same name in\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m    996\u001b[0m                                          \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcwd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 997\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    998\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1866\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1867\u001b[1;33m         \u001b[1;31m# explicitly inherit `$PATH`, on Windows too,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m         \u001b[1;31m# with `shell=False`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot.exe\" not found in path.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-43af8c5759df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#plot_model(model, to_file='./model_pics/' + m + '.png')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mSVG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'svg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;31m# pydot raises a generic Exception here,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# so no specific class can be caught.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[0;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "model_files = glob.glob('./saved_models/*.hdf5')\n",
    "for m in model_files:\n",
    "    print(m)\n",
    "    model = load_model(m)\n",
    "    #plot_model(model, to_file='./model_pics/' + m + '.png')\n",
    "    SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
