{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pushkar\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 16861204565460524075\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1499457126\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6074495061906963370\n",
      "physical_device_desc: \"device: 0, name: GeForce 940MX, pci bus id: 0000:01:00.0, compute capability: 5.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original image shape:  <PIL.Image.Image image mode=L size=224x224 at 0x1B186F856D8>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def plot_histogram(image):\n",
    "    hist,bins = np.histogram(image.flatten(),256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "    plt.plot(cdf_normalized, color = 'b')\n",
    "    plt.hist(image.flatten(),256,[0,256], color = 'r')\n",
    "    plt.xlim([0,256])\n",
    "    plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "    plt.show()\n",
    "\n",
    "def equalize_histogram(img, grid_size):\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    cl1 = clahe.apply(img)\n",
    "    return cl1\n",
    "\n",
    "# img = cv2.imread('./images/train/c0/img_34.jpg', 0)\n",
    "# equalized_img = equalize_histogram(img,16)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "# ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "def equalize_histogram(local_img, grid_size):\n",
    "#    local_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    equalized_img = clahe.apply(local_img)\n",
    "    return equalized_img\n",
    "\n",
    "def hisEqulColor(img):\n",
    "    ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\n",
    "    channels=cv2.split(ycrcb)\n",
    "    print (\"channels: \", len(channels))\n",
    "    cv2.equalizeHist(channels[0],channels[0])\n",
    "    cv2.merge(channels,ycrcb)\n",
    "    cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\n",
    "    return img\n",
    "    \n",
    "img = image.load_img('./images/train/c5/img_56.jpg', target_size=(224, 224), grayscale=True)\n",
    "print(\"original image shape: \", img)\n",
    "img = np.array(img)\n",
    "# eq_img = equalize_histogram(img,16)\n",
    "# plt.imshow(eq_img)\n",
    "# plt.show()\n",
    "# x = image.img_to_array(img)\n",
    "# print(x.shape)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "kernel = np.ones((8,8),np.uint8)\n",
    "gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "plt.imshow(gradient)\n",
    "plt.show()\n",
    "\n",
    "tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "plt.imshow(tophat)\n",
    "plt.show()\n",
    "\n",
    "blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "plt.imshow(blackhat)\n",
    "plt.show()\n",
    "\n",
    "dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "plt.imshow(dilation)\n",
    "plt.show()\n",
    "\n",
    "ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contour = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "plt.imshow(contour)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Images...\n",
      "Number of Categories:  10\n",
      "Categories:  ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
      "(15200,) (3800,) (15200,) (3800,)\n",
      "3800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import datetime, random, pickle\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, ActivityRegularization\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "import sys\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def loadImages(path):\n",
    "    data = load_files(path)\n",
    "    files = data['filenames']\n",
    "    targets = data['target']\n",
    "    target_names = data['target_names']\n",
    "    return files, targets, target_names\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    #equalize histogram\n",
    "    #equalized_img = equalize_histogram(img_array, 16)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    print (img_paths)\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "# ## Load the Data\n",
    "\n",
    "print (\"Loading Images...\")\n",
    "path = \"images/train\"\n",
    "files, targets, target_names = loadImages(path)\n",
    "# predict_files = np.array(glob(\"images/test/*\"))[1:10]\n",
    "print('Number of Categories: ', len(target_names))\n",
    "print('Categories: ', target_names)\n",
    "\n",
    "# Split the original training sets into training & testing sets\n",
    "train_files, test_files, train_targets, test_targets = train_test_split(files, targets, test_size=0.20, random_state=40)\n",
    "\n",
    "print(train_files.shape, test_files.shape, train_targets.shape, test_targets.shape)\n",
    "print(len(test_files))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating image tensors\n",
      "['images/train\\\\c3\\\\img_24663.jpg' 'images/train\\\\c8\\\\img_98810.jpg'\n",
      " 'images/train\\\\c9\\\\img_67390.jpg' ... 'images/train\\\\c7\\\\img_31727.jpg'\n",
      " 'images/train\\\\c7\\\\img_82756.jpg' 'images/train\\\\c5\\\\img_21995.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 15200/15200 [01:43<00:00, 147.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['images/train\\\\c5\\\\img_68264.jpg' 'images/train\\\\c6\\\\img_69335.jpg'\n",
      " 'images/train\\\\c2\\\\img_12280.jpg' ... 'images/train\\\\c8\\\\img_6916.jpg'\n",
      " 'images/train\\\\c6\\\\img_21610.jpg' 'images/train\\\\c5\\\\img_46343.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3800/3800 [00:30<00:00, 125.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train tensors: (15200, 224, 224, 3)\n",
      "Size of test tensors: (3800, 224, 224, 3)\n",
      "Size of test targets: (3800,)\n"
     ]
    }
   ],
   "source": [
    "print (\"Creating image tensors\")\n",
    "\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32') / 255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32') / 255\n",
    "\n",
    "train_targets_onehot = np_utils.to_categorical(np.array(train_targets), 10)\n",
    "test_targets_onehot = np_utils.to_categorical(np.array(test_targets), 10)\n",
    "\n",
    "print(\"Size of train tensors: \" + str(train_tensors.shape))\n",
    "print(\"Size of test tensors: \" + str(test_tensors.shape))\n",
    "print(\"Size of test targets: \" + str(test_targets.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./saved_models\\create_model102018-03-1684_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 79.50%\n",
      "./saved_models\\create_model112018-03-1879_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 40.71%\n",
      "./saved_models\\create_model112018-03-1976_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 86.97%\n",
      "./saved_models\\create_model12018-03-1446_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 19.21%\n",
      "./saved_models\\create_model12018-03-1551_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 21.26%\n",
      "./saved_models\\create_model12018-03-1714_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 31.00%\n",
      "./saved_models\\create_model122018-03-1921_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 73.71%\n",
      "./saved_models\\create_model132018-03-2055_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 27.18%\n",
      "./saved_models\\create_model142018-03-1959_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 77.18%\n",
      "./saved_models\\create_model152018-03-2034_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 92.18%\n",
      "./saved_models\\create_model152018-03-205_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 74.55%\n",
      "./saved_models\\create_model162018-03-2043_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 92.39%\n",
      "./saved_models\\create_model172018-03-2152_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.21%\n",
      "./saved_models\\create_model182018-03-2064_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 86.95%\n",
      "./saved_models\\create_model182018-03-2082_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model192018-03-2062_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 86.05%\n",
      "./saved_models\\create_model202018-03-2141_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 88.13%\n",
      "./saved_models\\create_model212018-03-2124_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model212018-03-2192_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model22018-03-1416_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 75.42%\n",
      "./saved_models\\create_model22018-03-1596_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 76.68%\n",
      "./saved_models\\create_model22018-03-3193_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 10.11%\n",
      "./saved_models\\create_model232018-03-2455_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.39%\n",
      "./saved_models\\create_model23dropout_0.052018-03-2423_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 22.74%\n",
      "./saved_models\\create_model23dropout_0.052018-03-2560_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 92.08%\n",
      "./saved_models\\create_model23dropout_0.052018-03-2753_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 92.71%\n",
      "./saved_models\\create_model23dropout_0.12018-03-2468_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 93.97%\n",
      "./saved_models\\create_model23dropout_0.12018-03-2571_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.37%\n",
      "./saved_models\\create_model23dropout_0.12018-03-2765_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 93.29%\n",
      "./saved_models\\create_model23dropout_0.152018-03-2466_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.84%\n",
      "./saved_models\\create_model23dropout_0.152018-03-259_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.34%\n",
      "./saved_models\\create_model23dropout_0.152018-03-2720_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.82%\n",
      "./saved_models\\create_model23dropout_0.22018-03-2417_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 89.95%\n",
      "./saved_models\\create_model23dropout_0.22018-03-258_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 89.84%\n",
      "./saved_models\\create_model23dropout_0.22018-03-2734_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.03%\n",
      "./saved_models\\create_model23dropout_0.252018-03-2475_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.55%\n",
      "./saved_models\\create_model23dropout_0.252018-03-2545_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.53%\n",
      "./saved_models\\create_model23dropout_0.252018-03-2742_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 89.37%\n",
      "./saved_models\\create_model23dropout_0.32018-03-2519_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 89.84%\n",
      "./saved_models\\create_model23dropout_0.32018-03-2716_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.45%\n",
      "./saved_models\\create_model23dropout_0.352018-03-256_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.58%\n",
      "./saved_models\\create_model23dropout_0.352018-03-2724_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.97%\n",
      "./saved_models\\create_model23dropout_0.42018-03-2585_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.55%\n",
      "./saved_models\\create_model242018-03-2465_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 88.84%\n",
      "./saved_models\\create_model24regularizer_0.052018-03-2585_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model24regularizer_0.12018-03-2560_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model24regularizer_0.152018-03-2516_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model24regularizer_0.22018-03-2583_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model25regularizer_0.052018-03-2530_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.16%\n",
      "./saved_models\\create_model25regularizer_0.12018-03-2587_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 83.79%\n",
      "./saved_models\\create_model25regularizer_0.152018-03-256_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.37%\n",
      "./saved_models\\create_model25regularizer_0.22018-03-2562_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 88.32%\n",
      "./saved_models\\create_model25regularizer_0.252018-03-2663_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 88.11%\n",
      "./saved_models\\create_model25regularizer_0.32018-03-2669_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 86.89%\n",
      "./saved_models\\create_model25regularizer_0.42018-03-2636_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.21%\n",
      "./saved_models\\create_model25regularizer_0.52018-03-2612_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 86.74%\n",
      "./saved_models\\create_model25regularizer_0.62018-03-2644_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.84%\n",
      "./saved_models\\create_model26dropout_0.052018-03-2674_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.24%\n",
      "./saved_models\\create_model26dropout_0.12018-03-2663_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.89%\n",
      "./saved_models\\create_model26dropout_0.152018-03-2640_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.00%\n",
      "./saved_models\\create_model26dropout_0.22018-03-2672_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.97%\n",
      "./saved_models\\create_model26dropout_0.252018-03-2658_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 80.53%\n",
      "./saved_models\\create_model26dropout_0.32018-03-2626_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 91.95%\n",
      "./saved_models\\create_model26dropout_0.352018-03-2619_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 90.08%\n",
      "./saved_models\\create_model26dropout_0.42018-03-2659_complete_model.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 87.79%\n",
      "./saved_models\\create_model32018-03-1545_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 69.45%\n",
      "./saved_models\\create_model42018-03-1539_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 61.26%\n",
      "./saved_models\\create_model52018-03-1575_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 74.34%\n",
      "./saved_models\\create_model62018-03-1582_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 68.79%\n",
      "./saved_models\\create_model82018-03-1768_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 9.76%\n",
      "./saved_models\\create_model92018-03-1723_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 55.26%\n",
      "./saved_models\\create_model92018-03-2235_model.best.from_scratch.hdf5\n",
      "Evaluating...\n",
      "Evaluation acc: 50.37%\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def predict_distraction(model):\n",
    "    print(\"Evaluating...\")\n",
    "    scores = model.evaluate(test_tensors, test_targets_onehot, verbose=0)\n",
    "    print(\"Evaluation %s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "    return\n",
    "\n",
    "model_files = glob.glob('./saved_models/create_model*.hdf5')\n",
    "for m in model_files:\n",
    "    if ('grayscale' not in m):\n",
    "        print(m)\n",
    "        model = load_model(m)\n",
    "        predict_distraction(model)\n",
    "    #p = model.predict(test_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(test_targets_onehot)\n",
    "#print(np.argmax(p, axis=0))\n",
    "# print(np.argmax(p[1,1:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "#model_files = glob.glob('./saved_models/*.hdf5')\n",
    "# for m in model_files:\n",
    "#     print(m)\n",
    "#     model = load_model(m)\n",
    "#     #plot_model(model, to_file='./model_pics/' + m + '.png')\n",
    "#     SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
