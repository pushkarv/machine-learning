{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from PIL import Image\n",
    "\n",
    "def plot_histogram(image):\n",
    "    hist,bins = np.histogram(image.flatten(),256,[0,256])\n",
    "\n",
    "    cdf = hist.cumsum()\n",
    "    cdf_normalized = cdf * hist.max()/ cdf.max()\n",
    "\n",
    "    plt.plot(cdf_normalized, color = 'b')\n",
    "    plt.hist(image.flatten(),256,[0,256], color = 'r')\n",
    "    plt.xlim([0,256])\n",
    "    plt.legend(('cdf','histogram'), loc = 'upper left')\n",
    "    plt.show()\n",
    "\n",
    "def equalize_histogram(img, grid_size):\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    cl1 = clahe.apply(img)\n",
    "    return cl1\n",
    "\n",
    "# img = cv2.imread('./images/train/c0/img_34.jpg', 0)\n",
    "# equalized_img = equalize_histogram(img,16)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "# ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "# plt.imshow(equalized_img)\n",
    "# plt.show()\n",
    "# plot_histogram(equalized_img)\n",
    "\n",
    "def equalize_histogram(local_img, grid_size):\n",
    "#    local_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    clahe = cv2.createCLAHE(tileGridSize=(grid_size,grid_size))\n",
    "    equalized_img = clahe.apply(local_img)\n",
    "    return equalized_img\n",
    "\n",
    "def hisEqulColor(img):\n",
    "    ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\n",
    "    channels=cv2.split(ycrcb)\n",
    "    print (\"channels: \", len(channels))\n",
    "    cv2.equalizeHist(channels[0],channels[0])\n",
    "    cv2.merge(channels,ycrcb)\n",
    "    cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\n",
    "    return img\n",
    "    \n",
    "def noisy(noise_typ,image):\n",
    "    if noise_typ == \"gauss\":\n",
    "      row,col,ch= image.shape\n",
    "      mean = .1\n",
    "      var = 0.1\n",
    "      sigma = var**0.1\n",
    "      gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "      gauss = gauss.reshape(row,col,ch)\n",
    "      noisy = image + gauss\n",
    "      return noisy\n",
    "    elif noise_typ == \"s&p\":\n",
    "      row,col,ch = image.shape\n",
    "      s_vs_p = 0.6\n",
    "      amount = 0.08\n",
    "      out = np.copy(image)\n",
    "      # Salt mode\n",
    "      num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "      coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 1\n",
    "\n",
    "      # Pepper mode\n",
    "      num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "      coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "      out[coords] = 0\n",
    "      return out\n",
    "    elif noise_typ == \"poisson\":\n",
    "      vals = len(np.unique(image))\n",
    "      vals = 2 ** np.ceil(np.log2(vals))\n",
    "      noisy = np.random.poisson(image * vals) / float(vals)\n",
    "      return noisy\n",
    "    elif noise_typ ==\"speckle\":\n",
    "      row,col,ch = image.shape\n",
    "      gauss = np.random.randn(row,col,ch)\n",
    "      gauss = gauss.reshape(row,col,ch)        \n",
    "      noisy = image + image * gauss\n",
    "      return noisy\n",
    "\n",
    "def shift(img):\n",
    "#     rows,cols,channels = img.shape\n",
    "#     M = np.float32([[1,0,1],[0,1,1]])\n",
    "#     img = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return img\n",
    "\n",
    "img = image.load_img('./images/train/c5/img_56.jpg', target_size=(224, 224), grayscale=False)\n",
    "print(\"original image shape: \", img)\n",
    "img2 = np.array(img)\n",
    "print(type(img2))\n",
    "# eq_img = equalize_histogram(img,16)\n",
    "# plt.imshow(eq_img)\n",
    "# plt.show()\n",
    "img = image.img_to_array(img) \n",
    "print(type(img))\n",
    "plt.imshow(img/255)\n",
    "plt.show()\n",
    "\n",
    "# kernel = np.ones((8,8),np.uint8)\n",
    "# gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "# plt.imshow(gradient)\n",
    "# plt.show()\n",
    "\n",
    "# tophat = cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)\n",
    "# plt.imshow(tophat)\n",
    "# plt.show()\n",
    "\n",
    "# blackhat = cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel)\n",
    "# plt.imshow(blackhat)\n",
    "# plt.show()\n",
    "\n",
    "# dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "# plt.imshow(dilation)\n",
    "# plt.show()\n",
    "\n",
    "# ret, thresh = cv2.threshold(img, 127, 255, 0)\n",
    "# im2, contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# contour = cv2.drawContours(img, contours, -1, (0,255,0), 3)\n",
    "# plt.imshow(contour)\n",
    "# plt.show()\n",
    "\n",
    "plt.imshow(noisy('gauss', img))\n",
    "plt.show()\n",
    "plt.imshow(noisy('s&p', img))\n",
    "plt.show()\n",
    "plt.imshow(noisy('poisson', img))\n",
    "plt.show()\n",
    "plt.imshow(noisy('speckle', img))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(shift(img/255))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "import datetime, random, pickle\n",
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "from PIL import ImageFile\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, ActivityRegularization\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "import sys\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "def loadImages(path):\n",
    "    data = load_files(path)\n",
    "    files = data['filenames']\n",
    "    targets = data['target']\n",
    "    target_names = data['target_names']\n",
    "    return files, targets, target_names\n",
    "\n",
    "\n",
    "def path_to_tensor(img_path, equalized=False, addNoise=False):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224), grayscale=equalized)\n",
    "    if (equalized == True):\n",
    "        img = np.array(img)\n",
    "        #equalize histogram\n",
    "        img = equalize_histogram(img, 16)\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    if (addNoise == True):\n",
    "        x = shift(x)\n",
    "#         x = noisy('gauss', x)\n",
    "#         if '34' in img_path:\n",
    "#             plt.imshow(x/255)\n",
    "#             plt.show()\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths, equalized=False,addNoise=False):\n",
    "    print (img_paths)\n",
    "    list_of_tensors = [path_to_tensor(img_path,equalized,addNoise) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)\n",
    "\n",
    "\n",
    "# dictionary for distraction category to numerical value\n",
    "catLabels = {\n",
    "    'c0': 'safe driving',\n",
    "    'c1': 'texting - right',\n",
    "    'c2': 'talking on the phone - right',\n",
    "    'c3': 'texting - left',\n",
    "    'c4': 'talking on the phone - left',\n",
    "    'c5': 'operating the radio',\n",
    "    'c6': 'drinking',\n",
    "    'c7': 'reaching behind',\n",
    "    'c8': 'hair and makeup',\n",
    "    'c9': 'talking to passenger'\n",
    "}\n",
    "\n",
    "#Maps category value to categorical label in the catLabels object\n",
    "def getClass(value):\n",
    "    index = 'c' + str(value)\n",
    "    return catLabels[index]\n",
    "\n",
    "def displayImage(sample_image):\n",
    "    gray = cv2.cvtColor(sample_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # convert BGR image to RGB for plotting\n",
    "    cv_rgb = cv2.cvtColor(sample_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(cv_rgb)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Images...\n",
      "Number of Categories:  10\n",
      "Categories:  ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
      "(15200,) (3800,) (15200,) (3800,)\n",
      "3800\n"
     ]
    }
   ],
   "source": [
    "# ## Load the Data\n",
    "\n",
    "print (\"Loading Images...\")\n",
    "path = \"C:/Users/pushkar/Documents/images/train\"\n",
    "files, targets, target_names = loadImages(path)\n",
    "# predict_files = np.array(glob(\"images/test/*\"))[1:10]\n",
    "print('Number of Categories: ', len(target_names))\n",
    "print('Categories: ', target_names)\n",
    "\n",
    "# Split the original training sets into training & testing sets\n",
    "train_files, test_files, train_targets, test_targets = train_test_split(files, targets, test_size=0.20, random_state=40)\n",
    "\n",
    "print(train_files.shape, test_files.shape, train_targets.shape, test_targets.shape)\n",
    "print(len(test_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def image_mean_var(img_path):\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x_mean = np.mean(x)\n",
    "    x_var = np.var(x)\n",
    "    return x_mean, x_var\n",
    "\n",
    "#iterate over the categories\n",
    "for c in target_names:\n",
    "    print(c)\n",
    "    #intensity mean for a category\n",
    "    c_files = glob.glob(path + '/' + c + '/*')\n",
    "    #intensity variance for a category\n",
    "    c_imgs_mean_var = [image_mean_var(img_path) for img_path in tqdm(c_files)]\n",
    "    print(c_imgs_mean_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"Creating image tensors\")\n",
    "\n",
    "train_tensors = paths_to_tensor(train_files,equalized=False,addNoise=True).astype('float32') / 255\n",
    "test_tensors = paths_to_tensor(test_files,equalized=False,addNoise=True).astype('float32') / 255\n",
    "\n",
    "train_targets_onehot = np_utils.to_categorical(np.array(train_targets), 10)\n",
    "test_targets_onehot = np_utils.to_categorical(np.array(test_targets), 10)\n",
    "\n",
    "print(\"Size of train tensors: \" + str(train_tensors.shape))\n",
    "print(\"Size of test tensors: \" + str(test_tensors.shape))\n",
    "print(\"Size of test targets: \" + str(test_targets.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "def predict_distraction(model):\n",
    "    print(\"Evaluating...\")\n",
    "    scores = model.evaluate(test_tensors, test_targets_onehot, verbose=0)\n",
    "    print(\"Evaluation %s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))\n",
    "    return\n",
    "\n",
    "#model_files = glob.glob('./saved_models/create_model*.hdf5')\n",
    "# for m in model_files:\n",
    "#     if ('grayscale' not in m):\n",
    "#         print(m)\n",
    "#         model = load_model(m)\n",
    "#         predict_distraction(model)\n",
    "    #p = model.predict(test_tensors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "#model_files = glob.glob('./saved_models/*.hdf5')\n",
    "# for m in model_files:\n",
    "#     print(m)\n",
    "#     model = load_model(m)\n",
    "#     #plot_model(model, to_file='./model_pics/' + m + '.png')\n",
    "#     SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "================\n",
    "Confusion matrix\n",
    "================\n",
    "\n",
    "Example of confusion matrix usage to evaluate the quality\n",
    "of the output of a classifier on the iris data set. The\n",
    "diagonal elements represent the number of points for which\n",
    "the predicted label is equal to the true label, while\n",
    "off-diagonal elements are those that are mislabeled by the\n",
    "classifier. The higher the diagonal values of the confusion\n",
    "matrix the better, indicating many correct predictions.\n",
    "\n",
    "The figures show the confusion matrix with and without\n",
    "normalization by class support size (number of elements\n",
    "in each class). This kind of normalization can be\n",
    "interesting in case of class imbalance to have a more\n",
    "visual interpretation of which class is being misclassified.\n",
    "\n",
    "Here the results are not as good as they could be as our\n",
    "choice for the regularization parameter C was not the best.\n",
    "In real life applications this parameter is usually chosen\n",
    "using :ref:`grid_search`.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "class_names = iris.target_names\n",
    "\n",
    "# Split the data into a training set and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Run classifier, using a model that is too regularized (C too low) to see\n",
    "# the impact on the results\n",
    "classifier = svm.SVC(kernel='linear', C=0.01)\n",
    "y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# # Compute confusion matrix\n",
    "# cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# np.set_printoptions(precision=2)\n",
    "\n",
    "# # Plot non-normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "#                       title='Confusion matrix, without normalization')\n",
    "\n",
    "# # Plot normalized confusion matrix\n",
    "# plt.figure()\n",
    "# plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "#                       title='Normalized confusion matrix')\n",
    "\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "labels = ['safe driving',\n",
    "            'texting right',\n",
    "            'phone - right',\n",
    "            'texting - left',\n",
    "            'phone - left',\n",
    "            'operating radio',\n",
    "            'drinking',\n",
    "            'reaching behind',\n",
    "            'hair & makeup',\n",
    "            'talking to passenger'\n",
    "]\n",
    "\n",
    "\n",
    "#num_images = 10\n",
    "model_files = glob.glob('./saved_models/create_base_model2018-04-0112_complete_model.hdf5')\n",
    "#model_files = glob.glob('./final_model/create_model23dropout_0.12018-03-2765_complete_model.hdf5')\n",
    "#model_files = glob.glob('./saved_models/create_model23_grayscaledropout_0.12018-03-2988_complete_model.hdf5')\n",
    "for m in model_files:\n",
    "    print(m)\n",
    "    model = load_model(m)\n",
    "#     print(model.summary())\n",
    "#     print(model.get_config())\n",
    "    p = model.predict(train_tensors)\n",
    "    predict_distraction(model)\n",
    "    print(\"True target\", train_targets_onehot)\n",
    "#    pcat = np_utils.to_categorical(np.array(p), 10)\n",
    "    print(\"Predicted target\", p)\n",
    "    matrix = confusion_matrix(train_targets, np.argmax(p,axis=1))\n",
    "    print(matrix)\n",
    "    plt.figure(figsize=(10,10), dpi=200)\n",
    "    plot_confusion_matrix(matrix, classes=labels, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "#     unlabeled_files = np.array(glob.glob(\"images/test/*2*\"))[1:num_images]\n",
    "#     print(unlabeled_files.shape)\n",
    "#     unlabeled_tensors = paths_to_tensor(unlabeled_files).astype('float32') / 255\n",
    "#     z = np.argmax(p, axis=1)\n",
    "#     for i in range(1,num_images-1):\n",
    "#         img = np.squeeze(np.array(unlabeled_tensors[i]))\n",
    "#         displayImage(img)\n",
    "#         print(\"Predicted class (above): \", getClass(z[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
